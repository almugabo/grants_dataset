{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eb6af3f",
   "metadata": {},
   "source": [
    "## Data acquisition - NSF funding data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b23696",
   "metadata": {},
   "source": [
    "## Step 1 : download files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c275778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import os \n",
    "import time \n",
    "\n",
    "\n",
    "def download_file(x_url, x_filename_local):\n",
    "    ''' download files,\n",
    "    e.g. zip files of XML\n",
    "\n",
    "    TO DO : add proxy options\n",
    "    '''\n",
    "    # NOTE the stream=True parameter\n",
    "    r = requests.get(x_url, stream=True)\n",
    "    with open(x_filename_local, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024):\n",
    "            if chunk:  # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "                f.flush()\n",
    "    # return x_filename_local\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37277b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "## N.B: THERE IS A PROBLEM WITH THE WEBSITE : \n",
    "## November 14. 2023 at 15:00 \n",
    "## https://www.nsf.gov/awardsearch/download?DownloadFileName=2001&All=true\n",
    "## one gets an error with \"This page is not available\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10535c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all done\n"
     ]
    }
   ],
   "source": [
    "# xUrl Paths \n",
    "xUrl_Path = 'https://www.nsf.gov/awardsearch/download?DownloadFileName='\n",
    "\n",
    "# Destionation folder \n",
    "xFld_Dest = '/home/mike/xTemp_data_infrastructure/_staging_funding_dataset/__downloaded/02_NSF'\n",
    "\n",
    "\n",
    "for x_year in [str(x) for x in range(2007, 2023)]:\n",
    "    x_UrlFile = xUrl_Path  + x_year + '&All=true'\n",
    "    #file_name \n",
    "    xfile_name = 'NSF_' + x_year + '.zip'\n",
    "    x_DestFileName =  os.path.join(xFld_Dest, xfile_name)\n",
    "    \n",
    "    time.sleep(1)\n",
    "    try:\n",
    "        download_file(x_UrlFile,  x_DestFileName )\n",
    "        #pass \n",
    "        \n",
    "    except:\n",
    "        print ('!!! error in:', x_year)\n",
    "\n",
    "print ('all done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f9c8bf",
   "metadata": {},
   "source": [
    "## STEP 2 : parse the downloaded data and save into an SQL database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d67c1149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58f6329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd \n",
    "import re\n",
    "import xmltodict\n",
    "import os \n",
    "import time \n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "168226be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_xml(xml_string):\n",
    "    try:\n",
    "        ET.fromstring(xml_string)\n",
    "        return True\n",
    "    except ET.ParseError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def flatten_dict(xdict):\n",
    "    # Convert the nested dictionary to a DataFrame\n",
    "    xdf = pd.json_normalize(xdict)\n",
    "    # this can converted back to a dictionary \n",
    "    xflat_dict = xdf.to_dict(orient='records')[0]\n",
    "    return xflat_dict\n",
    "\n",
    "def to_snake_case(s):\n",
    "    # Check if the string is already in snake_case\n",
    "    if re.search(r'[a-z][A-Z]', s):\n",
    "        # If camelCase patterns are found, convert to snake_case\n",
    "        snake_case_str = re.sub(r'(?<=[a-z])(?=[A-Z])', '_', s).lower()\n",
    "        return snake_case_str\n",
    "    else:\n",
    "        # If no camelCase patterns are found, return the original string\n",
    "        return s.lower()\n",
    "\n",
    "\n",
    "\n",
    "def nsf_process_record(xrecord_xml):\n",
    "    '''process one record of NSF grant\n",
    "    input: one xml record  \n",
    "    '''\n",
    "    \n",
    "    #### RESULT _LISTS \n",
    "        \n",
    "    xlst_lst_dict_grant_info = []\n",
    "    xlst_lst_dict_inst = []\n",
    "    xlst_lst_dict_investigators = []    \n",
    "    \n",
    "    # check if valid xml \n",
    "    \n",
    "    if is_valid_xml(xrecord_xml):\n",
    "        \n",
    "        q1 = xmltodict.parse(xrecord_xml)\n",
    "        q2 = q1.get('rootTag').get('Award')\n",
    "\n",
    "        xid = q2.get('AwardID')\n",
    "        #atomic_fields_str\n",
    "        xlst_fields_atomic = ['AwardID',  'AwardTitle',  'AbstractNarration', \n",
    "                               'AwardEffectiveDate',  'AwardExpirationDate', \n",
    "                              'MaxAmdLetterDate',  'MinAmdLetterDate',\n",
    "                               'AwardAmount',   'AwardTotalIntnAmount',\n",
    "                               'AGENCY',  'AWDG_AGCY_CODE',  'FUND_AGCY_CODE',\n",
    "                              'CFDA_NUM',      'NSF_PAR_USE_FLAG',  'TRAN_TYPE']\n",
    "        xlst_fields_to_flatten = ['Organization', 'ProgramOfficer', 'ProgramElement']\n",
    "\n",
    "\n",
    "\n",
    "        ### GRANT INFO \n",
    "        xdict_grant_info = {}\n",
    "        #add atomic values\n",
    "        for xfield in xlst_fields_atomic:\n",
    "            xfield_name = to_snake_case(xfield)\n",
    "            xdict_grant_info[xfield_name ] = q2.get(xfield)\n",
    "        #add instrument \n",
    "        xdict_grant_info['award_instrument'] = q2.get('AwardInstrument').get('Value')\n",
    "        ## add field to flatten \n",
    "        for xfield in xlst_fields_to_flatten:\n",
    "            if q2.get(xfield):\n",
    "                xfield_name = to_snake_case(xfield)\n",
    "                xdict_flat = flatten_dict(q2.get(xfield))\n",
    "                for xval in xdict_flat:\n",
    "                    xfield_name_2 = xval.lower().replace('.', '_')\n",
    "                    xdict_grant_info[xfield_name + '_' + xfield_name_2] = xdict_flat.get(xval)\n",
    "        ## fields to make sure they are lists \n",
    "        xlst_lst_dict_grant_info.append(xdict_grant_info)\n",
    "\n",
    "        ### INSTITUTION \n",
    "        if q2.get('Institution'):\n",
    "            xinst_list = q2.get('Institution')\n",
    "            if not isinstance(xinst_list, list):\n",
    "                xinst_list = [xinst_list]\n",
    "\n",
    "            for xinst in xinst_list:\n",
    "                xinst['award_id']= xid\n",
    "                xlst_lst_dict_inst.append(xinst)\n",
    "\n",
    "\n",
    "        ### INVESTIGATOR \n",
    "        if q2.get('Investigator'):\n",
    "            xinv_list = q2.get('Investigator')\n",
    "            if not isinstance(xinv_list, list):\n",
    "                xinv_list = [xinv_list]\n",
    "\n",
    "            for xinv in xinv_list:\n",
    "                xinv['award_id'] = xid\n",
    "                xlst_lst_dict_investigators.append(xinv)\n",
    "\n",
    "        \n",
    "    return xlst_lst_dict_grant_info, xlst_lst_dict_inst, xlst_lst_dict_investigators\n",
    "\n",
    "\n",
    "\n",
    "def nsf_process_zip_file(xFile):\n",
    "    '''\n",
    "    process NSF zipped file \n",
    "    returns: \n",
    "    three dataframes :\n",
    "    - df_grant\n",
    "    - df_inst\n",
    "    - df_inv\n",
    "    '''\n",
    "\n",
    "    ##XRESULTS_LIST \n",
    "\n",
    "    xRES_LST_GRANT = []\n",
    "    xRES_LST_INST = []\n",
    "    xRES_LST_RES = []\n",
    "\n",
    "    with zipfile.ZipFile(xFile, \"r\") as f:\n",
    "        for xnr, xname in enumerate(f.namelist()):\n",
    "            #if xnr == 110:\n",
    "            #    break \n",
    "\n",
    "            xdata = f.read(xname)\n",
    "\n",
    "            xid = xname.replace('.xml', '')\n",
    "            xgrant, xinst, xres = nsf_process_record(xdata)\n",
    "            xRES_LST_GRANT.extend(xgrant)\n",
    "            xRES_LST_INST.extend(xinst)\n",
    "            xRES_LST_RES.extend(xres)\n",
    "\n",
    "    df_grant = pd.DataFrame(xRES_LST_GRANT)\n",
    "    df_inst = pd.DataFrame(xRES_LST_INST)\n",
    "    df_inv = pd.DataFrame(xRES_LST_RES) \n",
    "\n",
    "    return df_grant, df_inst, df_inv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e6a2aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resulting database - we use sqlite for easy replication \n",
    "\n",
    "xPath_DB = '/home/mike/xTemp_data_infrastructure/_staging_funding_dataset/'\n",
    "xDB = xPath_DB  + 'grants_datasets.db'\n",
    "xDBCon = 'sqlite:///' + xDB\n",
    "\n",
    "\n",
    "\n",
    "## as there is a problem with the website \n",
    "## we use data downloaded earlier \n",
    "#xFld = '/home/mike/xTemp_data_infrastructure/_staging_funding_dataset/__downloaded/02_NSF/'\n",
    "\n",
    "xFld = '/media/mike/DATA4T/_data_repository/__others/__funding_data/5000_NSF/'\n",
    "\n",
    "xFiles = [xFld + x for x in os.listdir(xFld)]\n",
    "#xFile_rnd = random.sample(xFiles, 1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ab2d4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xFiles )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "264a7d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 14 15:41:26 2023\n",
      "processing: 2012\n",
      "processing: 2019\n",
      "processing: 2021\n",
      "processing: 2020\n",
      "processing: 2007\n",
      "processing: 2008\n",
      "processing: 2013\n",
      "processing: 2014\n",
      "processing: 2016\n",
      "processing: 2018\n",
      "processing: 2009\n",
      "processing: 2015\n",
      "processing: 2022\n",
      "processing: 2010\n",
      "processing: 2011\n",
      "processing: 2017\n",
      "all done!\n",
      "Tue Nov 14 15:44:33 2023\n"
     ]
    }
   ],
   "source": [
    "print(time.ctime())\n",
    "for xFile in xFiles:\n",
    "    \n",
    "    #if xFile != xFile_rnd:\n",
    "    #    continue \n",
    "    \n",
    "    xyear = xFile.split('/')[-1:][0].replace('.zip', '')\n",
    "    \n",
    "    print('processing:', xyear)\n",
    "    \n",
    "    xtab_name_suffix = 'nsf_' + xyear \n",
    "    \n",
    "    xtabname_grant = xtab_name_suffix + '_grant_info'\n",
    "    xtabname_inv   = xtab_name_suffix + '_grant_investigators'\n",
    "    xtabname_inst = xtab_name_suffix + '_grant_institutions'\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    dgrant, dinst, dinv = nsf_process_zip_file(xFile)\n",
    "    \n",
    "    \n",
    "    #print (xtabname_grant)\n",
    "    \n",
    "    ## save \n",
    "    dgrant.to_sql(name = xtabname_grant, con = xDBCon, if_exists='replace', index=False, chunksize=10000)\n",
    "    dinst.to_sql(name = xtabname_inst, con = xDBCon, if_exists='replace', index=False, chunksize=10000)\n",
    "    dinv.to_sql(name = xtabname_inv, con = xDBCon, if_exists='replace', index=False, chunksize=10000)    \n",
    "\n",
    "    \n",
    "    \n",
    "print('all done!')\n",
    "\n",
    "print(time.ctime()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d20921",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
